
  0%|                                                                                                                                                                                                                                | 0/950 [00:00<?, ?it/s]/home/clark/anaconda3/envs/musecoco/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|▏                                                                                                                                                                                                                     | 1/950 [00:16<4:21:58, 16.56s/it]Traceback (most recent call last):
  File "main.py", line 476, in <module>
    main()
  File "main.py", line 420, in main
    train_result = trainer.train(resume_from_checkpoint=checkpoint)
  File "/home/clark/anaconda3/envs/musecoco/lib/python3.8/site-packages/transformers/trainer.py", line 1543, in train
    return inner_training_loop(
  File "/home/clark/anaconda3/envs/musecoco/lib/python3.8/site-packages/transformers/trainer.py", line 1791, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
  File "/home/clark/anaconda3/envs/musecoco/lib/python3.8/site-packages/transformers/trainer.py", line 2539, in training_step
    loss = self.compute_loss(model, inputs)
  File "/home/clark/anaconda3/envs/musecoco/lib/python3.8/site-packages/transformers/trainer.py", line 2571, in compute_loss
    outputs = model(**inputs)
  File "/home/clark/anaconda3/envs/musecoco/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/clark/anaconda3/envs/musecoco/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py", line 167, in forward
    replicas = self.replicate(self.module, self.device_ids[:len(inputs)])
  File "/home/clark/anaconda3/envs/musecoco/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py", line 172, in replicate
    return replicate(module, device_ids, not torch.is_grad_enabled())
  File "/home/clark/anaconda3/envs/musecoco/lib/python3.8/site-packages/torch/nn/parallel/replicate.py", line 91, in replicate
    param_copies = _broadcast_coalesced_reshape(params, devices, detach)
  File "/home/clark/anaconda3/envs/musecoco/lib/python3.8/site-packages/torch/nn/parallel/replicate.py", line 71, in _broadcast_coalesced_reshape
    tensor_copies = Broadcast.apply(devices, *tensors)
  File "/home/clark/anaconda3/envs/musecoco/lib/python3.8/site-packages/torch/nn/parallel/_functions.py", line 23, in forward
    outputs = comm.broadcast_coalesced(inputs, ctx.target_gpus)
  File "/home/clark/anaconda3/envs/musecoco/lib/python3.8/site-packages/torch/nn/parallel/comm.py", line 58, in broadcast_coalesced
    return torch._C._broadcast_coalesced(tensors, devices, buffer_size)
KeyboardInterrupt